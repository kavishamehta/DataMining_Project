{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Mining_Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "JHqGz03IqRPN",
        "colab_type": "code",
        "outputId": "04ff91fc-5beb-4f60-81e8-9d02c281eb79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive\"\n",
        "path=\"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " 13bce0104\n",
            " 201811069_Resume.gdoc\n",
            " 201811069_resume.pdf\n",
            " 201811069_Resume.pdf\n",
            "'aadhar card.docx'\n",
            " Apti\n",
            "'assignment data'\n",
            "'Colab Notebooks'\n",
            "'Copy of DM _lab_00.py'\n",
            " CS18S35020085scoreCard.pdf\n",
            " CUB_200_2011\n",
            " Data_Preprocessing.ipynb\n",
            "'DLI C-FX-01 Certificate _ Deep Learning Institute.pdf'\n",
            "'DM _lab_00.py'\n",
            " ex2data1-logistic.xls\n",
            " faceimages.mat\n",
            "'final groups.xlsx'\n",
            " groups\n",
            " image_captioning\n",
            "'IT314-SE 2019 Attendance.gsheet'\n",
            "'IT485 Project Group.xlsx'\n",
            " lab3_2.ipynb\n",
            " lingspam_public\n",
            " lingspam_public.tar.gz\n",
            "'suesha gupta CV.doc'\n",
            "'Suesha Gupta Internship letter.pdf'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2l-7xX1JxwyQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import pandas\n",
        "import sklearn\n",
        "import pickle\n",
        "from wordcloud import WordCloud\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "#from sklearn.learning_curve import learning_curve\n",
        "import glob\n",
        "import errno"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1KsvmNnDygdA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ret(loc):\n",
        "    path =loc\n",
        "    files = glob.glob(path)\n",
        "    lst=[]\n",
        "    for fname in files:\n",
        "        try:\n",
        "            with open(fname,'r') as f:\n",
        "                lines = f.readlines()\n",
        "                str = '' \n",
        "                for i in range(2,len(lines)):\n",
        "                    str += lines[i].rstrip('\\n') \n",
        "                    lst.append(str)\n",
        "                f.close()\n",
        "        except IOError as exc:\n",
        "            if exc.errno != errno.EISDIR:\n",
        "                raise\n",
        "    return lst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WgSoBnu8ynWt",
        "colab_type": "code",
        "outputId": "1cae090f-fe61-4ac1-c6c5-c80584eb5a89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "data1=ret(path+'lingspam_public/bare/bare/part1/3*.txt')\n",
        "#ham=ret('/Users/abc/Desktop/machine learning/Models vectors/spam filter/Spam Dataset/Ham emails/*.txt')\n",
        "print(len(data1))\n",
        "df1 = pd.DataFrame({'mail':data1})\n",
        "data2=ret(path+'lingspam_public/bare/bare/part1/5*.txt')\n",
        "print(len(data2))\n",
        "df2 = pd.DataFrame({'mail':data2})\n",
        "data3=ret(path+'lingspam_public/bare/bare/part1/spm*.txt')\n",
        "spam=pd.DataFrame({'mail':data3})\n",
        "print(len(spam))\n",
        "ham=pd.concat([df1,df2],axis=0,ignore_index=True)\n",
        "len(ham)\n",
        "spam['type']=1\n",
        "ham['type']=0\n",
        "datap1=pd.concat([spam,ham],axis=0,ignore_index=True)\n",
        "print(datap1.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "143\n",
            "98\n",
            "48\n",
            "(289, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KYjzkoey4WjG",
        "colab_type": "code",
        "outputId": "b0fc4a6c-58eb-41ad-d542-fcbb5e32077a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "data1=ret(path+'lingspam_public/bare/bare/part2/5*.txt')\n",
        "#ham=ret('/Users/abc/Desktop/machine learning/Models vectors/spam filter/Spam Dataset/Ham emails/*.txt')\n",
        "print(len(data1))\n",
        "df1 = pd.DataFrame({'mail':data1})\n",
        "data2=ret(path+'lingspam_public/bare/bare/part2/6*.txt')\n",
        "print(len(data2))\n",
        "df2 = pd.DataFrame({'mail':data2})\n",
        "data3=ret(path+'lingspam_public/bare/bare/part2/spm*.txt')\n",
        "spam=pd.DataFrame({'mail':data3})\n",
        "print(len(spam))\n",
        "ham=pd.concat([df1,df2],axis=0,ignore_index=True)\n",
        "len(ham)\n",
        "spam['type']=1\n",
        "ham['type']=0\n",
        "datap2=pd.concat([spam,ham],axis=0,ignore_index=True)\n",
        "print(datap2.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "194\n",
            "47\n",
            "48\n",
            "(289, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "soefMnJ55V-6",
        "colab_type": "code",
        "outputId": "b0e4f08a-7f60-48d3-dc70-a43403459346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "cell_type": "code",
      "source": [
        "data1=ret(path+'lingspam_public/bare/bare/part3/6*.txt')\n",
        "#ham=ret('/Users/abc/Desktop/machine learning/Models vectors/spam filter/Spam Dataset/Ham emails/*.txt')\n",
        "print(len(data1))\n",
        "df1 = pd.DataFrame({'mail':data1})\n",
        "\n",
        "data3=ret(path+'lingspam_public/bare/bare/part3/spm*.txt')\n",
        "spam=pd.DataFrame({'mail':data3})\n",
        "print(len(spam))\n",
        "#ham=pd.concat([df1,df2],axis=0,ignore_index=True)\n",
        "len(ham)\n",
        "spam['type']=1\n",
        "ham['type']=0\n",
        "datap3=pd.concat([spam,df1],axis=0,ignore_index=True)\n",
        "print(datap3.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "241\n",
            "48\n",
            "(289, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q51p2Nlh51Bu",
        "colab_type": "code",
        "outputId": "75650f96-4202-4a43-faf3-e457f7ad1e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "data1=ret(path+'lingspam_public/bare/bare/part4/6*.txt')\n",
        "#ham=ret('/Users/abc/Desktop/machine learning/Models vectors/spam filter/Spam Dataset/Ham emails/*.txt')\n",
        "print(len(data1))\n",
        "df1 = pd.DataFrame({'mail':data1})\n",
        "data2=ret(path+'lingspam_public/bare/bare/part4/8*.txt')\n",
        "print(len(data2))\n",
        "df2 = pd.DataFrame({'mail':data2})\n",
        "data3=ret(path+'lingspam_public/bare/bare/part4/spm*.txt')\n",
        "spam=pd.DataFrame({'mail':data3})\n",
        "print(len(spam))\n",
        "ham=pd.concat([df1,df2],axis=0,ignore_index=True)\n",
        "len(ham)\n",
        "spam['type']=1\n",
        "ham['type']=0\n",
        "datap4=pd.concat([spam,ham],axis=0,ignore_index=True)\n",
        "print(datap4.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "209\n",
            "32\n",
            "48\n",
            "(289, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "unaJ9K6r6A97",
        "colab_type": "code",
        "outputId": "bbd0490a-0b43-426e-9794-2f37e0cf157c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "data1=ret(path+'lingspam_public/bare/bare/part5/8*.txt')\n",
        "#ham=ret('/Users/abc/Desktop/machine learning/Models vectors/spam filter/Spam Dataset/Ham emails/*.txt')\n",
        "print(len(data1))\n",
        "df1 = pd.DataFrame({'mail':data1})\n",
        "data2=ret(path+'lingspam_public/bare/bare/part5/9*.txt')\n",
        "print(len(data2))\n",
        "df2 = pd.DataFrame({'mail':data2})\n",
        "data3=ret(path+'lingspam_public/bare/bare/part5/spm*.txt')\n",
        "spam=pd.DataFrame({'mail':data3})\n",
        "print(len(spam))\n",
        "ham=pd.concat([df1,df2],axis=0,ignore_index=True)\n",
        "len(ham)\n",
        "spam['type']=1\n",
        "ham['type']=0\n",
        "datap5=pd.concat([spam,ham],axis=0,ignore_index=True)\n",
        "print(datap5.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59\n",
            "183\n",
            "48\n",
            "(290, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3krvhoUX6Tv7",
        "colab_type": "code",
        "outputId": "2e39b251-d3c1-44a1-8bba-a3b5f00d4324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data=pd.concat([datap1,datap2,datap3,datap4,datap5],axis=0,ignore_index=True)\n",
        "print(data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1446, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5-jvL09Z6tW1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d5ZiyXVC0Ci-",
        "colab_type": "code",
        "outputId": "3a106cc6-431a-4cfc-c01e-2525cb0ac486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data=data.drop_duplicates(subset=['mail'])\n",
        "data.shape #25 duplicates mail"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1439, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "_WNNlL3_0HI0",
        "colab_type": "code",
        "outputId": "161b4d19-a706-461a-b580-13e6ceef4729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop = set(stopwords.words('english'))#english.txt file has stopwords\n",
        "print(stop)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "{'than', 'there', 'me', 'do', 'nor', 'ours', 'having', 'below', 'until', 'have', 'this', 'during', 'through', 'now', 've', \"it's\", 'here', 'his', 'few', \"didn't\", 'yourself', 'its', 'am', \"shan't\", 'it', 'very', \"you'd\", 'and', \"weren't\", 'is', 'own', \"you'll\", 'these', 'same', \"needn't\", 'at', 'she', 'm', 'her', 'themselves', 'or', 'into', 'don', 'shouldn', 'against', 'because', 'why', 'doing', 'haven', 'needn', 'o', 'yours', 'all', 'won', \"doesn't\", 'when', 'shan', 'both', 'how', \"don't\", 'weren', 'should', 'to', 'out', 'then', 'hers', 'while', \"hadn't\", 'isn', 'ain', 'our', \"you're\", 'once', 'them', 'each', 'most', 'that', 'after', 'itself', 'from', \"mightn't\", 'where', 'theirs', 'what', \"won't\", 'about', \"wouldn't\", 'above', 'll', \"that'll\", 'down', 'hasn', 'been', 'being', 'in', 's', 'd', 'mustn', 'who', 'before', 'by', 'he', \"you've\", 'those', 'further', 'wasn', \"haven't\", 'himself', 'you', \"shouldn't\", \"hasn't\", 'some', 'hadn', 'my', \"wasn't\", \"couldn't\", 'myself', 'just', 'had', 'of', \"aren't\", 're', 'an', 'yourselves', 'him', 'herself', 'the', 'too', 'no', 'be', 'i', 't', 'ma', 'we', 'any', 'not', 'doesn', \"mustn't\", 'over', 'up', 'y', 'does', 'were', 'was', 'but', 'has', 'for', 'didn', 'on', 'such', 'ourselves', 'are', 'off', 'can', 'as', 'with', \"isn't\", 'so', 'their', 'couldn', 'if', 'your', 'under', 'wouldn', \"should've\", 'which', \"she's\", 'mightn', 'other', 'only', 'whom', 'did', 'aren', 'will', 'they', 'between', 'a', 'again', 'more'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wk1Uq1us0OhJ",
        "colab_type": "code",
        "outputId": "8cc8d258-efaa-44d2-a316-82af9d40baa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "lst = [\"wouldn't\",'won', 'nor', 'not', 'against',\"doesn't\",\"don't\"] #to remove these words from english.txt file\n",
        "for word in lst:\n",
        "    stop.remove(word)\n",
        "print(stop)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'than', 'there', 'me', 'do', 'ours', 'having', 'below', 'until', 'have', 'this', 'during', 'through', 'now', 've', \"it's\", 'here', 'his', 'few', \"didn't\", 'yourself', 'its', 'am', \"shan't\", 'it', 'very', \"you'd\", 'and', \"weren't\", 'is', 'own', \"you'll\", 'these', 'same', \"needn't\", 'at', 'she', 'm', 'her', 'themselves', 'or', 'into', 'don', 'shouldn', 'because', 'why', 'doing', 'haven', 'needn', 'o', 'yours', 'all', 'when', 'shan', 'both', 'how', 'weren', 'should', 'to', 'out', 'then', 'hers', 'while', \"hadn't\", 'isn', 'ain', 'our', \"you're\", 'once', 'them', 'each', 'most', 'that', 'after', 'itself', 'from', \"mightn't\", 'where', 'theirs', 'what', \"won't\", 'about', 'above', 'll', \"that'll\", 'down', 'hasn', 'been', 'being', 'in', 's', 'd', 'mustn', 'who', 'before', 'by', 'he', \"you've\", 'those', 'further', 'wasn', \"haven't\", 'himself', 'you', \"shouldn't\", \"hasn't\", 'some', 'hadn', 'my', \"wasn't\", \"couldn't\", 'myself', 'just', 'had', 'of', \"aren't\", 're', 'an', 'yourselves', 'him', 'herself', 'the', 'too', 'no', 'be', 'i', 't', 'ma', 'we', 'any', 'doesn', \"mustn't\", 'over', 'up', 'y', 'does', 'were', 'was', 'but', 'has', 'for', 'didn', 'on', 'such', 'ourselves', 'are', 'off', 'can', 'as', 'with', \"isn't\", 'so', 'their', 'couldn', 'if', 'your', 'under', 'wouldn', \"should've\", 'which', \"she's\", 'mightn', 'other', 'only', 'whom', 'did', 'aren', 'will', 'they', 'between', 'a', 'again', 'more'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aADrRGx60TQc",
        "colab_type": "code",
        "outputId": "fb894140-30a3-41f6-870f-8186672fb5a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "sno = nltk.stem.SnowballStemmer('english') #english stemmer\n",
        "sno.stem(\"caring\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'care'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "UFdy0EgY0Z6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk \n",
        "#removal of html tags\n",
        "def cleanhtml(sent):\n",
        "    cleanr=re.compile('<.*?>')\n",
        "    cleantext=re.sub(cleanr,' ',sent)\n",
        "    return cleantext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O_I_pMMk0dD6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#removal of punctuation tags\n",
        "def cleanpunc(sent):\n",
        "    cleaned=re.sub(r'[?|@|!|^|%|\\'|\"|#|$|:|*|+|-|=|\\-|&|_]',r'',sent)\n",
        "    cleaned=re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
        "    return cleaned"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xd1-PcQJ0izd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocessing(series):\n",
        "    \n",
        "    i = 0\n",
        "    str1=\" \"\n",
        "    final_string = []    ## This list will contain cleaned sentences\n",
        "    list_of_sent = []    ## This is a list of lists used as input to the W2V model at a later stage\n",
        "    \n",
        "    ## Creating below lists for future use\n",
        "    all_positive_words=[] # store words from spam mail here\n",
        "    all_negative_words=[] # store words from ham mail here\n",
        "    \n",
        "\n",
        "    for sent in series.values:\n",
        "        filtered_sent=[]\n",
        "        sent=cleanhtml(sent)\n",
        "        sent=cleanpunc(sent)\n",
        "        \n",
        "        for clean_word in sent.split():\n",
        "            if((clean_word.isalpha()) and (len(clean_word)>2)):\n",
        "                if(clean_word.lower() not in stop):\n",
        "                    s=(sno.stem(clean_word.lower()))\n",
        "                    s=clean_word.lower()\n",
        "                    filtered_sent.append(s)\n",
        "                    if(data['type'].values)[i]==1:\n",
        "                        all_positive_words.append(s)\n",
        "                    if(data['type'].values)[i]==0:\n",
        "                        all_negative_words.append(s)\n",
        "                        \n",
        "        list_of_sent.append(filtered_sent)\n",
        "        str1=' '.join(filtered_sent)\n",
        "        final_string.append(str1)\n",
        "        i+=1\n",
        "    return final_string,list_of_sent\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ARHJsT10nir",
        "colab_type": "code",
        "outputId": "4c2996af-5a93-4457-b994-39f17ee0c4c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1094
        }
      },
      "cell_type": "code",
      "source": [
        "final_string,list_of_sent=preprocessing(data['mail'])\n",
        "print(data['mail'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       dear nlpeople , i ' m sure you ' ll agree auto...\n",
            "1       * * * * * * * * * * * * * * * we have display ...\n",
            "2       attention ! warning ! adults only ! warning ! ...\n",
            "3       if you want the best hunting and camping vacat...\n",
            "4       57 million email addresses for only $ 99 you w...\n",
            "5       make $ 3500 per week using your home computer ...\n",
            "6       hi . my name is dennis . i am a third-generati...\n",
            "7       attention ! warning ! adults only ! warning ! ...\n",
            "8       * have you ever got a speeding ticket and need...\n",
            "9       from the desk of robert g . allen dear nlpeopl...\n",
            "10      subject : re : are you in debt ? if you are th...\n",
            "11      = = = = = = = = = = = = = = = = = = = = = = = ...\n",
            "12      57 million email addresses for only $ 99 you w...\n",
            "13      the 2 newest and hottest interactive adult web...\n",
            "14      special : work from home , sell successfully a...\n",
            "15      it was just released ! ! introducing . . . mil...\n",
            "16      hey , i ' ll just get to the point . i have a ...\n",
            "17      the rumors are true ! * * * * * * * * * * * * ...\n",
            "18      authenticated sender is subject : ( + ( + bull...\n",
            "19      there was a way to : pay off a 30 year mortgag...\n",
            "20      this is a multi-part message in mime format . ...\n",
            "21      pardon the intrusion . no offence is meant . i...\n",
            "22      federally mandated , electric deregulation , a...\n",
            "23      horizon publishing would like to invite you to...\n",
            "24      have you ever been treated bad or embarrased b...\n",
            "25      attention ! warning ! adults only ! warning ! ...\n",
            "26      this message complies with the proposed united...\n",
            "27      order form : all addresses are fresh and clean...\n",
            "28      bad credit ? no credit ? bankruptcy ? divorce ...\n",
            "29      great news for advertisers and bulkers ! ! ! !...\n",
            "                              ...                        \n",
            "1416    the three books listed below are in the lingui...\n",
            "1417    the english language in pakistan edited by rob...\n",
            "1418    the three books listed below are in the lingui...\n",
            "1419    in this message we ask your attention for the ...\n",
            "1420    the 13th pacific asia conference on language ,...\n",
            "1421    lang acquisition ( universal grammar ) investi...\n",
            "1422    phonetics intonation ( second edition ) alan c...\n",
            "1423    pidgins and creoles muehlhausler , peter , ed ...\n",
            "1424    table of contents of glot international , vol ...\n",
            "1425    the two books listed below are in the linguist...\n",
            "1426    - - - - - - - - - - - - - - - - - - - - - - se...\n",
            "1427    atomism and binding edited by hans bennis , pi...\n",
            "1428    t e f l i n the association of teachers of eng...\n",
            "1429    roberto bolognesi , the phonology of campidani...\n",
            "1430    the 1998 central japan language education work...\n",
            "1431    please post or distribute call for papers comp...\n",
            "1432    we are pleased to inform you that the center f...\n",
            "1433    kluwer academic publishers text , speech and l...\n",
            "1434    announcing the 1999 conference on the morpho -...\n",
            "1435    2nd and last call for papers - - - - - - - - -...\n",
            "1436    program sposs 24-26 september , la baume - les...\n",
            "1437    call for papers eurogp ' 99 second european wo...\n",
            "1438    ruben van de vijver , the iambic issue . iambs...\n",
            "1439    literacy development in a multilingual context...\n",
            "1440    the glow phonology workshop phonetics in phono...\n",
            "1441    call for papers special conference on johann l...\n",
            "1442    * * anthropological linguistics , volume 40 , ...\n",
            "1443    the first international conference on tai stud...\n",
            "1444    social and cognitive approaches to interperson...\n",
            "1445    the new psychology of language cognitive and f...\n",
            "Name: mail, Length: 1439, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3U1F-0vE0_AC",
        "colab_type": "code",
        "outputId": "d33edc0d-e434-4ae1-de85-d30666d4d88e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data['cleaned_mail_stem']=final_string\n",
        "print(data.shape)\n",
        "#data.head(10)\n",
        "data.dropna()\n",
        "data.dropna(axis='columns')\n",
        "data.shape\n",
        "data = data.fillna(method='ffill')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1439, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "laFDnKyY1Fab",
        "colab_type": "code",
        "outputId": "f40b30a8-786d-4ef4-9236-1946fcc7cfd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import csr_matrix\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(data['cleaned_mail_stem'])\n",
        "sp_arr = csr_matrix(vectors)\n",
        "sdf = pd.SparseDataFrame(sp_arr,default_fill_value=0)\n",
        "print(sdf.head())\n",
        "print(vectors.shape)\n",
        "vectors[0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0      1      2      3      4      5      6      7      8      9      \\\n",
            "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
            "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
            "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
            "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
            "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
            "\n",
            "   ...    38133  38134  38135  38136  38137  38138  38139  38140  38141  38142  \n",
            "0  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "1  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "2  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "3  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "4  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
            "\n",
            "[5 rows x 38143 columns]\n",
            "(1439, 38143)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x38143 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 98 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "fUotLQhzxLxa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bow_vect=CountVectorizer()\n",
        "bow=bow_vect.fit_transform(data['cleaned_mail_stem'].values)\n",
        "sp_arr1 = csr_matrix(bow)\n",
        "sdfb = pd.SparseDataFrame(sp_arr1,default_fill_value=0)\n",
        "#print(sdfb.head())\n",
        "x=bow  \n",
        "y=data['type'].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OzPhpznJ1yV7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "Xb_train, Xb_test, yb_train, yb_test = train_test_split(sdfb, data['type'], test_size=0.20, random_state=111)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gFbKUUH711-w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(sdf, data['type'], test_size=0.20, random_state=111)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HVyw-W_i2Nv3",
        "colab_type": "code",
        "outputId": "22c4e82f-0897-4ce4-b757-c8c96b4ef1e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3386
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print (X_train)\n",
        "print (X_test.shape)\n",
        "print (y_train.shape)\n",
        "print (y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         0      1      2      3      4      5      6      7        8      \\\n",
            "699   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "354   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "564   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "484   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "106   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "1081  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "1423  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "407   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "961   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "125   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "768   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "1280  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "633   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "883   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "425   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "490   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "246   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "126   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "314   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "119   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "987   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "385   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "1262  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "1405  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "556   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "383   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "87    0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "694   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "638   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "154   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "...        ...    ...    ...    ...    ...    ...    ...    ...      ...   \n",
            "483   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "324   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "747   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "562   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "525   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "344   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "334   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "685   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "268   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "972   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.36253   \n",
            "37    0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "712   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "1045  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "418   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "1294  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "1308  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "728   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "1290  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "1292  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "1031  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "953   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "967   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "808   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "118   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "1346  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "681   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "1299  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "86    0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "724   0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "876   0.175292    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.00000   \n",
            "\n",
            "      9      ...    38133  38134     38135  38136  38137  38138  38139  38140  \\\n",
            "699     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "354     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "564     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "484     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "106     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "1081    0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "1423    0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "407     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "961     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "125     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "768     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "1280    0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "633     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "883     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "425     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "490     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "246     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "126     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "314     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "119     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "987     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "385     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "1262    0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "1405    0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "556     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "383     0.0  ...      0.0    0.0  0.049317    0.0    0.0    0.0    0.0    0.0   \n",
            "87      0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "694     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "638     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "154     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "...     ...  ...      ...    ...       ...    ...    ...    ...    ...    ...   \n",
            "483     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "324     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "747     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "562     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "525     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "344     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "334     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "685     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "268     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "972     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "37      0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "712     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "1045    0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "418     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "1294    0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "1308    0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "728     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "1290    0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "1292    0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "1031    0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "953     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "967     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "808     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "118     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "1346    0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "681     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "1299    0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "86      0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "724     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "876     0.0  ...      0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
            "\n",
            "      38141  38142  \n",
            "699     0.0    0.0  \n",
            "354     0.0    0.0  \n",
            "564     0.0    0.0  \n",
            "484     0.0    0.0  \n",
            "106     0.0    0.0  \n",
            "1081    0.0    0.0  \n",
            "1423    0.0    0.0  \n",
            "407     0.0    0.0  \n",
            "961     0.0    0.0  \n",
            "125     0.0    0.0  \n",
            "768     0.0    0.0  \n",
            "1280    0.0    0.0  \n",
            "633     0.0    0.0  \n",
            "883     0.0    0.0  \n",
            "425     0.0    0.0  \n",
            "490     0.0    0.0  \n",
            "246     0.0    0.0  \n",
            "126     0.0    0.0  \n",
            "314     0.0    0.0  \n",
            "119     0.0    0.0  \n",
            "987     0.0    0.0  \n",
            "385     0.0    0.0  \n",
            "1262    0.0    0.0  \n",
            "1405    0.0    0.0  \n",
            "556     0.0    0.0  \n",
            "383     0.0    0.0  \n",
            "87      0.0    0.0  \n",
            "694     0.0    0.0  \n",
            "638     0.0    0.0  \n",
            "154     0.0    0.0  \n",
            "...     ...    ...  \n",
            "483     0.0    0.0  \n",
            "324     0.0    0.0  \n",
            "747     0.0    0.0  \n",
            "562     0.0    0.0  \n",
            "525     0.0    0.0  \n",
            "344     0.0    0.0  \n",
            "334     0.0    0.0  \n",
            "685     0.0    0.0  \n",
            "268     0.0    0.0  \n",
            "972     0.0    0.0  \n",
            "37      0.0    0.0  \n",
            "712     0.0    0.0  \n",
            "1045    0.0    0.0  \n",
            "418     0.0    0.0  \n",
            "1294    0.0    0.0  \n",
            "1308    0.0    0.0  \n",
            "728     0.0    0.0  \n",
            "1290    0.0    0.0  \n",
            "1292    0.0    0.0  \n",
            "1031    0.0    0.0  \n",
            "953     0.0    0.0  \n",
            "967     0.0    0.0  \n",
            "808     0.0    0.0  \n",
            "118     0.0    0.0  \n",
            "1346    0.0    0.0  \n",
            "681     0.0    0.0  \n",
            "1299    0.0    0.0  \n",
            "86      0.0    0.0  \n",
            "724     0.0    0.0  \n",
            "876     0.0    0.0  \n",
            "\n",
            "[1151 rows x 38143 columns]\n",
            "(288, 38143)\n",
            "(1151,)\n",
            "(288,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1151, 38143)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "metadata": {
        "id": "EXEZOhKV4xl7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "evke4drw43GI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "svc = SVC(kernel='linear', gamma=1.0)\n",
        "#knc = KNeighborsClassifier(n_neighbors=49)\n",
        "mnb = MultinomialNB(alpha=0.2)\n",
        "#dtc = DecisionTreeClassifier(min_samples_split=7, random_state=111)\n",
        "#lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
        "#rfc = RandomForestClassifier(n_estimators=31, random_state=111)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fl-R48WH46q8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clfs = {'SVC' : svc, 'NB':mnb}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m6HKZtb3718B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(clf, features, targets):    \n",
        "    clf.fit(features, targets)\n",
        "\n",
        "def predict(clf, features):\n",
        "    return (clf.predict(features))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O5k4wuDBypPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score #works\n",
        "pred_scoresbag_word_vectors = []\n",
        "predbag =dict()\n",
        "for k,v in clfs.items():\n",
        "    train(v, Xb_train, yb_train)\n",
        "    pred = predict(v, Xb_test)\n",
        "    predbag[k]=pred\n",
        "    pred_scoresbag_word_vectors.append((k, [accuracy_score(yb_test , pred)]))\n",
        "#predbag['SVC']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i6Swao5q6vli",
        "colab_type": "code",
        "outputId": "2a97ecdf-467f-426b-9f05-a5d55b0e994b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score #works\n",
        "pred_scores_word_vectors = []\n",
        "prednew =dict()\n",
        "for k,v in clfs.items():\n",
        "    train(v, X_train, y_train)\n",
        "    pred = predict(v, X_test)\n",
        "    print(pred)\n",
        "    prednew[k]=pred\n",
        "    pred_scores_word_vectors.append((k, [accuracy_score(y_test , pred)]))\n",
        "#prednew['SVC']\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_oz16EjkzQ18",
        "colab_type": "code",
        "outputId": "075ff26a-7f16-46d3-c0b1-6057387a2981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "predictionsbag = pd.DataFrame.from_items(pred_scoresbag_word_vectors,orient='index', columns=['Score'])\n",
        "\n",
        "\n",
        "print(predictionsbag)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Score\n",
            "SVC  0.708333\n",
            "NB   0.774306\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "fxz5SZDw1AD_",
        "colab_type": "code",
        "outputId": "a585370f-3782-4cd4-9a23-5ed38927cddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "for k,v in clfs.items():\n",
        "  print(confusion_matrix(y_test, prednew[k]))\n",
        "  print(precision_recall_fscore_support(y_test, prednew[k],average='macro')) #for Tf-Idf using svm and logistic_regression"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[192   5]\n",
            " [ 48  43]]\n",
            "(0.8479166666666667, 0.723573380933787, 0.7487117857201653, None)\n",
            "[[193   4]\n",
            " [ 45  46]]\n",
            "(0.8654621848739497, 0.7425949684832933, 0.7699192956713132, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l_lldBQO6zSs",
        "colab_type": "code",
        "outputId": "f79d1c58-d0c3-48e4-9091-3b4d540d9af9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "predictions = pd.DataFrame.from_items(pred_scores_word_vectors,orient='index', columns=['Score'])\n",
        "\n",
        "\n",
        "print(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Score\n",
            "SVC  0.815972\n",
            "NB   0.829861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "cALb3qiO3fcu",
        "colab_type": "code",
        "outputId": "65228a84-5bb5-4982-8086-1b80cd383b92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "for k,v in clfs.items():\n",
        "  print(confusion_matrix(yb_test, predbag[k]))\n",
        "  print(precision_recall_fscore_support(yb_test, predbag[k],average='macro'))#for CountVectorizer in svm and logistic Regression\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[151  46]\n",
            " [ 38  53]]\n",
            "(0.6671476671476672, 0.6744575221732583, 0.6701390782656123, None)\n",
            "[[164  33]\n",
            " [ 32  59]]\n",
            "(0.739019520851819, 0.7404194789981593, 0.7397071705668878, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jm0xJ9cpB4bz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def find(p):\n",
        "    if p == 1:\n",
        "        print (\"E-mail is SPAM\")\n",
        "    else:\n",
        "        print (\"E-mail is NOT Spam\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RGSXfl0o2Jod",
        "colab_type": "code",
        "outputId": "3cc16c11-b081-425a-89ad-65b74d8570ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "text = [\"Free tones Hope you enjoyed your new content\"]\n",
        "integers = bow_vect.transform(text)\n",
        "sp_arr2 = csr_matrix(integers)\n",
        "sdf2 = pd.SparseDataFrame(sp_arr2,default_fill_value=0)\n",
        "p = svc.predict(sdf2)[0]\n",
        "find(p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E-mail is SPAM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EW_ICMLJB_CA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text = [\"Free tones Hope you enjoyed your new content\"]\n",
        "integers = vectorizer.transform(text)\n",
        "sp_arr1 = csr_matrix(integers)\n",
        "sdf1 = pd.SparseDataFrame(sp_arr1,default_fill_value=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hT5SoYc5CGzZ",
        "colab_type": "code",
        "outputId": "ffee0373-3b5e-4eee-93d4-3d207bbd0236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "p = svc.predict(sdf1)[0]\n",
        "find(p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E-mail is SPAM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FDCkxzsY4uqj",
        "colab_type": "code",
        "outputId": "a88262eb-41e3-44f4-e6e8-87af00ad303c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "cell_type": "code",
      "source": [
        "cross_validation_svc=[]\n",
        "cross_validation_svc=cross_val_score(svc, Xb_train, yb_train, cv=3, n_jobs=-1)#cross-validation using 3-folds by count vectorizer method using svm\n",
        "print(np.mean(cross_validation_svc))\n",
        "cross_validation_svc=[]\n",
        "cross_validation_svc=cross_val_score(svc, Xb_train, yb_train, cv=5, n_jobs=-1)#cross-validation using 5-folds by count vectorizer method using svm\n",
        "print(np.mean(cross_validation_svc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7637109626665762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7576284584980237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bkoSoKy5pppg",
        "colab_type": "code",
        "outputId": "9864b434-7762-49b7-f31c-5626fd8ffe96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "cell_type": "code",
      "source": [
        "cross_validation_svc3=[]\n",
        "cross_validation_svc3=cross_val_score(svc, X_train, y_train, cv=3, n_jobs=-1)\n",
        "print(cross_validation_svc3)\n",
        "acc3=np.mean(cross_validation_svc3)\n",
        "print(acc3)\n",
        "cross_validation_svc2=[]\n",
        "cross_validation_svc2=cross_val_score(svc, X_train, y_train, cv=5, n_jobs=-1)#The number of CPUs to use to do the computation.\n",
        "#None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. \n",
        "print(cross_validation_svc2)\n",
        "acc1=np.mean(cross_validation_svc2)\n",
        "print(acc1)\n",
        "#cross-validation using 3-folds and 5-folds  by tf-idf using svm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.81298701 0.83289817 0.81984334]\n",
            "0.8219095091157754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.81385281 0.84347826 0.82608696 0.82608696 0.80434783]\n",
            "0.8227705627705628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xHGY8PmmwTZw",
        "colab_type": "code",
        "outputId": "5fbd05e7-8ace-4784-8715-a489f00b80f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "cell_type": "code",
      "source": [
        "cross_validation_lr1=[]\n",
        "cross_validation_lr1=cross_val_score(mnb,X_train, y_train, cv=3, n_jobs=-1)\n",
        "print(np.mean(cross_validation_lr1))\n",
        "cross_validation_lr2=[]\n",
        "cross_validation_lr2=cross_val_score(mnb, X_train, y_train, cv=5, n_jobs=-1)    \n",
        "print(np.mean(cross_validation_lr2))\n",
        "#cross-validation for naive-bayes using folds 3 and 5 for tf-idf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8236411108473772\n",
            "0.8262337662337662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HgVBdl7liqTi",
        "colab_type": "code",
        "outputId": "ced816bf-7628-4ce3-cc69-5e69cea214b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "cross_validation_lr1=[]\n",
        "cross_validation_lr1=cross_val_score(mnb, Xb_train, yb_train, cv=3, n_jobs=-1)\n",
        "print(np.mean(cross_validation_lr1))\n",
        "cross_validation_lr2=[]\n",
        "cross_validation_lr2=cross_val_score(mnb, Xb_train, yb_train, cv=5, n_jobs=-1)\n",
        "print(np.mean(cross_validation_lr2))\n",
        "#cross-validation for naive-bayes using folds 3 and 5 for CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7862353486374373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7784490871447394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RAtF1ZWtkMMF",
        "colab_type": "code",
        "outputId": "43a63ab0-f7f8-448a-e942-5093e1f92c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "cell_type": "code",
      "source": [
        "predictions.plot(kind='bar', ylim=(0.5,1.0), figsize=(9,6), align='center', colormap=\"Accent\")\n",
        "plt.xticks(np.arange(2), predictions.index)\n",
        "print(predictions)\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.title('Distribution by Classifier')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.) #Distribution by classifier for TF-IDF"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Score\n",
            "SVC  0.815972\n",
            "NB   0.829861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc85ce1c438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoIAAAF/CAYAAADdFKhPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQUmSpEYZBCVJkhr1/wHD2T3Ckgbs/gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "yo2Zm4IyoQ1i",
        "colab_type": "code",
        "outputId": "a16f4b68-af3d-4820-e073-b84412d76c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "cell_type": "code",
      "source": [
        "predictionsbag.plot(kind='bar', ylim=(0.5,0.9), figsize=(9,6), align='center', colormap=\"Accent\")\n",
        "plt.xticks(np.arange(2), predictions.index)\n",
        "print(predictionsbag)\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.title('Distribution by Classifier')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.) #Distribution by classifier for CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Score\n",
            "SVC  0.708333\n",
            "NB   0.774306\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc869da6ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAogAAAF/CAYAAADKNjiGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xu4XmV95//3JwkQEEGQ4IFTUBMh\ngkgJ1J/UIwXRMmDVUagHaLWM/YkoWhWniohjf9qOreNPVCKlIoqI4mioKIIHcKqOCZWDCQZDEEmA\nIZIAcibkO388a8OztjvJk7hXHpL9fl3Xc+217nX6PjtXrnxy3+teK1WFJEmSNGLSsAuQJEnSY4sB\nUZIkSS0GREmSJLUYECVJktRiQJQkSVKLAVGSJEktBkRpE5Pks0k+ME7n2j3J3UkmN+s/TPLm8Th3\nc75vJzl2vM7Xd97PJ/lv433eYVyr+f0/rVneOsmFSe5M8tUkr0vy3a6uLUlrMmXYBUh6VJJfA08C\nVgEPAwuBLwBzqmo1QFW9ZT3O9eaqunRN+1TVb4Bt/7CqH7neqcAzqur1fed/2Xicu0tJArwNOB7Y\nE1gJ/AQ4raqu6fr6VdX/+381vT//J1bVqqbtS13XIEmj2YMoPfb8p6p6PLAH8FHgvcC/jPdFkvgf\nxJ7/AbwdOBHYEZgJfAP4syHUsgdwXV843GAjvcKStCEMiNJjVFXdWVVzgdcCxybZB9pDnkl2SvJv\nSe5IsiLJj5JMSnIOsDtwYTOE+Z4k05NUkjcl+Q3w/b62/rD49CQ/S3JXkm8m2bG51ouSLO2vMcmv\nk/xpksOB/wq8trneVc32R4asm7ren+TGJLcl+UKS7ZttI3Ucm+Q3SX6b5O/W8SvaKcklSX6X5LIk\nezTnOj3Jx0fVOTfJSaNPkGQG8FbgmKr6flU9UFX3VtWXquqjY+y/Q/P7Xp5kZbO8a9/245IsaWq6\nIcnrmvZnNDXe2Xy3r/QdU832DwGn9P0O39Sc73/17btX851XJFmU5DV92z6f5DNJLkpyD/Didfz+\nJGmNDIjSY1xV/QxYCjx/jM3varZNozc0+V97h9QbgN/Q643ctqr+oe+YFwJ7Ay9dwyXfCPwV8BR6\nQ92fHKDG7wB/D3ylud5+Y+x2XPN5MfA0ekPbnxq1z58AzwQOAU5JsvdaLvs64MPATsCVPDoUezZw\nTJJJ0AvRwJ8C545xjkOApc3veBCTgH+l19O3O3DfyHdI8jh6v6uXNT3Az2vqoqnzu8AOwK7A/z/6\nxFX1Qdq/w1avcXP+S5rvsTNwNPDpJLP6dvsL4CPA44H/hSRtIAOitGm4md7w52gP0Qtye1TVQ1X1\no1r3C9ZPrap7quq+NWw/p6p+UVX3AB8AXjNOw5WvA/6pqpZU1d3A+4CjR/Vefqiq7quqq4CrgLGC\n5ohvVdXlVfUA8HfA/5Nktybs3Ukv/EEvSP2wqv7PGOd4InDLoF+gqm6vqguaXsbf0QtjL+zbZTWw\nT5Ktq+qWqlrQtD9EL1Q+tarur6oNCW9HAL+uqn+tqlVV9XPgAuA/9+3zzar696paXVX3b8A1JAkw\nIEqbil2AFWO0/yOwGPhuM7R58gDnumk9tt8IbEGvl+4P9dTmfP3nnkKv53PErX3L97L2CTSP1NkE\nzhXNNaDXizgyWeb1wDlrOMft9AL2QJJsk+SMZpj8LuBy4AlJJjeB+rXAW4BbknwryV7Noe8BAvws\nyYIkfzXoNfvsAfxxczvBHUnuoBe6n9y3z7r+bCVpIAZE6TEuyYH0AuLv9TpV1e+q6l1V9TTgSOCd\nSUZ6ztbUk7iuHsbd+pZ3p9f79VvgHmCbvrom0xvaHvS8N9MLOf3nXgWM1bM3iEfqTLItvR7Wm5um\nLwJHJdmP3nD6N9Zwju8BuyaZPeA130VvCPyPq2o74AUjJQBU1cVVdSi90PlL4HNN+61V9ddV9VTg\nv9AbGn7GgNcccRNwWVU9oe+zbVX9Td8+6/ozkKSBGBClx6gk2yU5AjgP+OJYj1xJckQzwSH0hlUf\npjfMCb3g9bQNuPTrk8xKsg1wGvC1qnoYuA6YmuTPkmwBvB/Yqu+4/wNMH7n3bwxfBk5KsmcT6Ebu\nt9vQGbsvT/InSbakd4/fT6vqJoCqWgrMo9dzeMGahtOr6lfAp4EvN5NwtkwyNcnRa+iNfTy9+w7v\naCbvfHBkQ5InJTmquVfwAeBumj+LJP+5bzLLSnpBbjXr59+AmUnekGSL5nPgOu7TlKQNYkCUHnsu\nTPI7ej1Gfwf8E/CXa9h3BnApvTDyE+DTVfWDZtv/B7y/GY782/W4/jnA5+kN906l9/gXqupO4P8F\nzgSW0etR7J/V/NXm5+1J/mOM857VnPty4AbgfnrPH9xQ59ILaCuAA3h0SHnE2cC+rHl4ecSJ9Caa\nnA7cAVwP/Dlw4Rj7fgLYml6P6k+B7/RtmwS8k14v5gp69yaO9O4dCPzvJHcDc4G3V9WSdX7DPs09\nj4fRu6fyZnp/Ph+jHdIlaVxk3fezS9KmJ8kL6A017zHAxB1JUh97ECVtdpoh8LcDZxoOJWn9dRoQ\nkxzePMx18Vj38yTZI8n3klyd3gN1+x84e2ySXzWfcX+Xq6TNU3NP3h30Jop8YsjlSNImqbMh5maG\n43XAofTuU5pH720FC/v2+Srwb1V1dpKXAH9ZVW9obv6eD8ymdzP3FcABVbWyk2IlSZL0iC57EA8C\nFjcPxX2Q3kzMo0btMwv4frP8g77tLwUuqaoVTSi8BDi8w1olSZLU6DIg7kL7oa1Lm7Z+VwGvbJb/\nHHh8kicOeKwkSZI6MGXdu3Tqb4FPJTmO3qMvltF7jttAkhwPHA/wuMc97oC99tprHUdIkqRNxRVX\nXPHbqpq27j3/oGvsPGXKlDOBfZhYk3dXA79YtWrVmw844IDbRm/sMiAuo/1Ghl2btkdU1c00PYjN\ng3NfVVV3JFkGvGjUsT8cfYGqmgPMAZg9e3bNnz9/HMuXJEnDlOTGde/1h5kyZcqZT37yk/eeNm3a\nykmTJk2Ypx6sXr06y5cvn3XrrbeeSe9NXC1dJuV5wIzmrQlb0nu469z+HZLs1PfWhffRe5AuwMXA\nYUl2SLIDvYfDXtxhrZIkaWLaZ9q0aXdNpHAIMGnSpJo2bdqd9HpOf397VxduXp91Ar1gdy1wflUt\nSHJakpGk+iJgUZLrgCcBH2mOXUHv1Vnzms9pTZskSdJ4mjTRwuGI5nuPmQU7vQexqi4CLhrVdkrf\n8teAr63h2LN4tEdRkiRps/Te9773yRdccMETJ02aVJMmTeLTn/70jS95yUvuGWZNw56kIkmS9Jhx\n6s9OPWBcz3fQqVesbfull176uIsvvvgJ11xzzcKtt966brnllikPPPBANvR6Dz30EFtsscWGHv6I\niTRbR5Ik6TFl2bJlW+y4446rtt566wJ4ylOesmr69OkPXXbZZdvsv//+ez3zmc+cte++++69cuXK\nSffee29e/epXT585c+asvffee9aFF174eIBPfvKTT3zJS17yjOc+97kzn/e85z0T4AMf+MCT9tln\nn71nzpw566STTnrq+tZlQJQkSRqSV7ziFXfdfPPNW06fPn2f17/+9bt/61vf2vb+++/P6173uqd/\n4hOf+M2iRYsWXnbZZYu23Xbb1R/72Md2TsJ111238Nxzz11y/PHHT7/33nsDsGDBgm2++c1vXj9v\n3rxFX//617dbvHjx1Kuvvvraa6+9duGVV165zbe//e1t16cuA6IkSdKQbL/99qt/8YtfLPzUpz51\n47Rp01Yde+yxT//4xz8+beedd37ohS984b0AO+644+otttiCH//4x9u+4Q1vuB1g//33v/+pT33q\ng9dcc81UgOc///l3PelJT3oY4Dvf+c52l19++XazZs2a9axnPWvW9ddfP/WXv/zl1PWpy3sQJUmS\nhmjKlCkcccQRvzviiCN+9+xnP/u+z372s+v9cPBtttlm9chyVfGOd7zjlne/+92/3dCa7EGUJEka\nkquuumqra665ZquR9Z///Odbz5gx4/7bbrtti8suu2wbgJUrV0566KGHOPjgg+/+4he/uCPA1Vdf\nvdUtt9yy5bOf/ez7R5/zZS972V3nnHPOTnfeeeckgBtuuGGLZcuWrVenoD2IkiRJQ3LXXXdNPvHE\nE3e/6667Jk+ePLmmT5/+wNlnn33jdddd99sTTzxx9/vvv3/S1KlTV19++eXXvec977ntjW984x4z\nZ86cNXnyZM4444xfj0xu6ffKV77yrgULFkw98MAD94Je7+KXvvSlG3bZZZdVg9aVqs3j2ZC+ak+S\npM1LkiuqanaX17jqqqt+vd9++23wUOym7qqrrtppv/32mz663SFmSZIktRgQJUmS1GJAlCRJUosB\nUZIkTWSrV69evcGvttuUNd979VjbDIiSJGki+8Xy5cu3n2ghcfXq1Vm+fPn2wC/G2u5jbiRJ0oS1\natWqN996661n3nrrrfswsTrOVgO/WLVq1ZvH2mhAlCRJE9YBBxxwG3DksOt4rJlISVmSJEkDMCBK\nkiSpxYAoSZKkFgOiJEmSWgyIkiRJajEgSpIkqcWAKEmSpBYDoiRJkloMiJIkSWoxIEqSJKnFgChJ\nkqQWA6IkSZJaDIiSJElqMSBKkiSpxYAoSZKkFgOiJEmSWgyIkiRJauk0ICY5PMmiJIuTnDzG9t2T\n/CDJz5NcneTlTfv0JPclubL5fLbLOiVJkvSoKV2dOMlk4HTgUGApMC/J3Kpa2Lfb+4Hzq+ozSWYB\nFwHTm23XV9VzuqpPkiRJY+uyB/EgYHFVLamqB4HzgKNG7VPAds3y9sDNHdYjSZKkAXQZEHcBbupb\nX9q09TsVeH2SpfR6D9/Wt23PZuj5siTPH+sCSY5PMj/J/OXLl49j6ZIkSRPXsCepHAN8vqp2BV4O\nnJNkEnALsHtV7Q+8Ezg3yXajD66qOVU1u6pmT5s2baMWLkmStLnqMiAuA3brW9+1aev3JuB8gKr6\nCTAV2KmqHqiq25v2K4DrgZkd1ipJkqRGlwFxHjAjyZ5JtgSOBuaO2uc3wCEASfamFxCXJ5nWTHIh\nydOAGcCSDmuVJElSo7NZzFW1KskJwMXAZOCsqlqQ5DRgflXNBd4FfC7JSfQmrBxXVZXkBcBpSR4C\nVgNvqaoVXdUqSZKkR6Wqhl3DuJg9e3bNnz9/2GVIkqRxkuSKqpo97DomomFPUpEkSdJjjAFRkiRJ\nLQZESZIktRgQJUmS1GJAlCRJUosBUZIkSS0GREmSJLUYECVJktRiQJQkSVKLAVGSJEktBkRJkiS1\nGBAlSZLUYkCUJElSiwFRkiRJLQZESZIktRgQJUmS1GJAlCRJUosBUZIkSS0GREmSJLUYECVJktRi\nQJQkSVKLAVGSJEktBkRJkiS1GBAlSZLUYkCUJElSiwFRkiRJLQZESZIktRgQJUmS1GJAlCRJUosB\nUZIkSS0GREmSJLUYECVJktTSaUBMcniSRUkWJzl5jO27J/lBkp8nuTrJy/u2va85blGSl3ZZpyRJ\nkh41pasTJ5kMnA4cCiwF5iWZW1UL+3Z7P3B+VX0mySzgImB6s3w08CzgqcClSWZW1cNd1StJkqSe\nLnsQDwIWV9WSqnoQOA84atQ+BWzXLG8P3NwsHwWcV1UPVNUNwOLmfJIkSepYlwFxF+CmvvWlTVu/\nU4HXJ1lKr/fwbetxLEmOTzI/yfzly5ePV92SJEkT2rAnqRwDfL6qdgVeDpyTZOCaqmpOVc2uqtnT\npk3rrEhJkqSJpLN7EIFlwG5967s2bf3eBBwOUFU/STIV2GnAYyVJktSBLnsQ5wEzkuyZZEt6k07m\njtrnN8AhAEn2BqYCy5v9jk6yVZI9gRnAzzqsVZIkSY3OehCralWSE4CLgcnAWVW1IMlpwPyqmgu8\nC/hckpPoTVg5rqoKWJDkfGAhsAp4qzOYJUmSNo708timb/bs2TV//vxhlyFJksZJkiuqavaw65iI\nhj1JRZIkSY8xBkRJkiS1GBAlSZLUYkCUJElSiwFRkiRJLQZESZIktRgQJUmS1GJAlCRJUosBUZIk\nSS0GREmSJLUYECVJktRiQJQkSVKLAVGSJEktBkRJkiS1GBAlSZLUMmXYBUiSBnPqz04ddgkaglMP\nOnXYJWgCsgdRkiRJLQZESZIktRgQJUmS1GJAlCRJUosBUZIkSS0GREmSJLUYECVJktRiQJQkSVKL\nAVGSJEktBkRJkiS1GBAlSZLUYkCUJElSiwFRkiRJLQZESZIktRgQJUmS1GJAlCRJUkunATHJ4UkW\nJVmc5OQxtv9zkiubz3VJ7ujb9nDftrld1ilJkqRHTenqxEkmA6cDhwJLgXlJ5lbVwpF9quqkvv3f\nBuzfd4r7quo5XdUnSZKksXXZg3gQsLiqllTVg8B5wFFr2f8Y4Msd1iNJkqQBdBkQdwFu6ltf2rT9\nniR7AHsC3+9rnppkfpKfJnnFGo47vtln/vLly8erbkmSpAntsTJJ5Wjga1X1cF/bHlU1G/gL4BNJ\nnj76oKqaU1Wzq2r2tGnTNlatkiRJm7UuA+IyYLe+9V2btrEczajh5apa1vxcAvyQ9v2JkiRJ6kiX\nAXEeMCPJnkm2pBcCf282cpK9gB2An/S17ZBkq2Z5J+BgYOHoYyVJkjT+BgqISf4kyV82y9OS7Lmu\nY6pqFXACcDFwLXB+VS1IclqSI/t2PRo4r6qqr21vYH6Sq4AfAB/tn/0sSZKk7qzzMTdJPgjMBp4J\n/CuwBfBFer16a1VVFwEXjWo7ZdT6qWMc92Ng33WdX5IkSeNvkB7EPweOBO4BqKqbgcd3WZQkSZKG\nZ5CA+GAz/FsASR7XbUmSJEkapkEC4vlJzgCekOSvgUuBz3VbliRJkoZlnfcgVtV/T3IocBe9+xBP\nqapLOq9MkiRJQ7HWgNi8T/nSqnoxYCiUJEmaANY6xNy82WR1ku03Uj2SJEkasnUOMQN3A9ckuYRm\nJjNAVZ3YWVWSJEkamkEC4tebjyRJkiaAQSapnN28Km9m07Soqh7qtixJkiQNyyBvUnkRcDbwayDA\nbkmOrarLuy1NkiRJwzDIEPPHgcOqahFAkpnAl4EDuixMkiRJwzHIg7K3GAmHAFV1Hb33MUuSJGkz\nNEgP4vwkZwJfbNZfB8zvriRJkiQN0yAB8W+AtwIjj7X5EfDpziqSJEnSUA0SEKcA/6Oq/gkeebvK\nVp1WJUmSpKEZ5B7E7wFb961vDVzaTTmSJEkatkEC4tSquntkpVnepruSJEmSNEyDBMR7kvzRyEqS\nA4D7uitJkiRJwzTIPYjvAL6a5GZ6D8p+MvDaTquSJEnS0Azyqr15SfYCntk0+ao9SZKkzdgah5iT\nHJjkyQBNIPwj4CPAx5PsuJHqkyRJ0ka2tnsQzwAeBEjyAuCjwBeAO4E53ZcmSZKkYVjbEPPkqlrR\nLL8WmFNVFwAXJLmy+9IkSZI0DGvrQZycZCRAHgJ8v2/bIJNbJEmStAlaW9D7MnBZkt/Se6zNjwCS\nPIPeMLMkSZI2Q2sMiFX1kSTfA54CfLeqqtk0CXjbxihOkiRJG99ah4qr6qdjtF3XXTmSJEkatkHe\npCJJkqQJxMkmm4FTf3bqsEvQEJx60KnDLkGStJlaZw9ikrcl2WFjFCNJkqThG2SI+UnAvCTnJzk8\nSbouSpIkScOzzoBYVe8HZgD/AhwH/CrJ3yd5+rqObQLloiSLk5w8xvZ/TnJl87kuyR19245N8qvm\nc+x6fStJkiRtsIHuQayqSnIrcCuwCtgB+FqSS6rqPWMdk2QycDpwKLCUXi/k3Kpa2Hfek/r2fxuw\nf7O8I/BBYDZQwBXNsSs34DtKkiRpPQxyD+Lbk1wB/APw78C+VfU3wAHAq9Zy6EHA4qpaUlUPAucB\nR61l/2PoPZwb4KXAJVW1ogmFlwCHr/PbSJIk6Q82SA/ijsArq+rG/saqWp3kiLUctwtwU9/6UuCP\nx9oxyR7Anjz6Or+xjt1lgFolSZL0Bxpkksq3gRUjK0m2S/LHAFV17TjVcTTwtap6eH0OSnJ8kvlJ\n5i9fvnycSpEkSZrYBgmInwHu7lu/u2lbl2XAbn3ruzZtYzmaR4eXBz62quZU1eyqmj1t2rQBSpIk\nSdK6DBIQ0/ceZqpqNYMNTc8DZiTZM8mW9ELg3N87ebIXvUkvP+lrvhg4LMkOzTMYD2vaJEmS1LFB\nAuKSJCcm2aL5vB1Ysq6DqmoVcAK9YHctcH5VLUhyWpIj+3Y9GjhvVAhdAXyYXsicB5zWtEmSJKlj\ng/QEvgX4JPB+eo+c+R5w/CAnr6qLgItGtZ0yav3UNRx7FnDWINeRJEnS+FlnQKyq2+j18kmSJGkC\nWGdATDIVeBPwLGDqSHtV/VWHdUmSJGlIBrkH8RzgyfQeXn0ZvRnFv+uyKEmSJA3PIAHxGVX1AeCe\nqjob+DPW8MBrSZIkbfoGCYgPNT/vSLIPsD2wc3clSZIkaZgGmcU8p3kW4fvpPcdwW+ADnVYlSZKk\noVlrQEwyCbirqlYClwNP2yhVSZIkaWjWOsTcvDXlPRupFkmSJD0GDHIP4qVJ/jbJbkl2HPl0Xpkk\nSZKGYpB7EF/b/HxrX1vhcLMkSdJmaZA3qey5MQqRJEnSY8Mgb1J541jtVfWF8S9HkiRJwzbIEPOB\nfctTgUOA/wAMiJIkSZuhQYaY39a/nuQJwHmdVSRJkqShGmQW82j3AN6XKEmStJka5B7EC+nNWoZe\noJwFnN9lUZIkSRqeQe5B/O99y6uAG6tqaUf1SJIkacgGCYi/AW6pqvsBkmydZHpV/brTyiRJkjQU\ng9yD+FVgdd/6w02bJEmSNkODBMQpVfXgyEqzvGV3JUmSJGmYBgmIy5McObKS5Cjgt92VJEmSpGEa\n5B7EtwBfSvKpZn0pMObbVSRJkrTpG+RB2dcDz02ybbN+d+dVSZIkaWjWOcSc5O+TPKGq7q6qu5Ps\nkOS/bYziJEmStPENcg/iy6rqjpGVqloJvLy7kiRJkjRMgwTEyUm2GllJsjWw1Vr2lyRJ0iZskEkq\nXwK+l+Rfm/W/BL7QXUmSJEkapkEmqXwsyVXAnzZNH66qi7stS5IkScMySA8iVfUd4DsASf4kyelV\n9dZOK5MkSdJQDBQQk+wPHAO8BrgB+HqXRUmSJGl41hgQk8ykFwqPoffmlK8AqaoXb6TaJEmSNARr\n60H8JfAj4IiqWgyQ5KSNUpUkSZKGZm2PuXklcAvwgySfS3IIkPU5eZLDkyxKsjjJyWvY5zVJFiZZ\nkOTcvvaHk1zZfOauz3UlSZK04dbYg1hV3wC+keRxwFHAO4Cdk3wG+J9V9d21nTjJZOB04FB672+e\nl2RuVS3s22cG8D7g4KpamWTnvlPcV1XP2dAvJkmSpA2zzgdlV9U9VXVuVf0nYFfg58B7Bzj3QcDi\nqlpSVQ8C59ELmv3+Gji9eTsLVXXbelUvSZKkcTfIm1QeUVUrq2pOVR0ywO67ADf1rS9t2vrNBGYm\n+fckP01yeN+2qUnmN+2vGOsCSY5v9pm/fPny9fkqkiRJWoOBHnPT8fVnAC+i1zt5eZJ9m3c/71FV\ny5I8Dfh+kmuq6vr+g6tqDjAHYPbs2bVxS5ckSdo8rVcP4npaBuzWt75r09ZvKTC3qh6qqhuA6+gF\nRqpqWfNzCfBDYP8Oa5UkSVKjy4A4D5iRZM8kWwJHA6NnI3+DXu8hSXaiN+S8JMkOSbbqaz8YWIgk\nSZI619kQc1WtSnICcDEwGTirqhYkOQ2YX1Vzm22HJVkIPAy8u6puT/I84Iwkq+mF2I/2z36WJElS\ndzq9B7GqLgIuGtV2St9yAe9sPv37/BjYt8vaJEmSNLYuh5glSZK0CTIgSpIkqcWAKEmSpBYDoiRJ\nkloMiJIkSWoxIEqSJKnFgChJkqQWA6IkSZJaDIiSJElqMSBKkiSpxYAoSZKkFgOiJEmSWgyIkiRJ\najEgSpIkqcWAKEmSpBYDoiRJkloMiJIkSWoxIEqSJKnFgChJkqQWA6IkSZJaDIiSJElqMSBKkiSp\nxYAoSZKkFgOiJEmSWgyIkiRJajEgSpIkqcWAKEmSpBYDoiRJkloMiJIkSWoxIEqSJKnFgChJkqQW\nA6IkSZJaOg2ISQ5PsijJ4iQnr2Gf1yRZmGRBknP72o9N8qvmc2yXdUqSJOlRU7o6cZLJwOnAocBS\nYF6SuVW1sG+fGcD7gIOramWSnZv2HYEPArOBAq5ojl3ZVb2SJEnq6bIH8SBgcVUtqaoHgfOAo0bt\n89fA6SPBr6pua9pfClxSVSuabZcAh3dYqyRJkhpdBsRdgJv61pc2bf1mAjOT/HuSnyY5fD2OJcnx\nSeYnmb98+fJxLF2SJGniGvYklSnADOBFwDHA55I8YdCDq2pOVc2uqtnTpk3rqERJkqSJpcuAuAzY\nrW9916at31JgblU9VFU3ANfRC4yDHCtJkqQOdBkQ5wEzkuyZZEvgaGDuqH2+Qa/3kCQ70RtyXgJc\nDByWZIckOwCHNW2SJEnqWGezmKtqVZIT6AW7ycBZVbUgyWnA/Kqay6NBcCHwMPDuqrodIMmH6YVM\ngNOqakVXtUqSJOlRnQVEgKq6CLhoVNspfcsFvLP5jD72LOCsLuuTJEnS7xv2JBVJkiQ9xhgQJUmS\n1GJAlCRJUosBUZIkSS0GREmSJLUYECVJktRiQJQkSVKLAVGSJEktBkRJkiS1GBAlSZLUYkCUJElS\niwFRkiRJLQZESZIktRgQJUmS1GJAlCRJUosBUZIkSS0GREmSJLUYECVJktRiQJQkSVKLAVGSJEkt\nBkRJkiS1GBAlSZLUYkCUJElSiwFRkiRJLQZESZIktRgQJUmS1GJAlCRJUosBUZIkSS0GREmSJLUY\nECVJktRiQJQkSVKLAVGSJEktnQbEJIcnWZRkcZKTx9h+XJLlSa5sPm/u2/ZwX/vcLuuUJEnSo6Z0\ndeIkk4HTgUOBpcC8JHOrauGoXb9SVSeMcYr7quo5XdUnSZKksXXZg3gQsLiqllTVg8B5wFEdXk+S\nJEnjoMuAuAtwU9/60qZttFcluTrJ15Ls1tc+Ncn8JD9N8oqxLpDk+Gaf+cuXLx/H0iVJkiauYU9S\nuRCYXlXPBi4Bzu7btkdVzQZqRyT/AAAF40lEQVT+AvhEkqePPriq5lTV7KqaPW3atI1TsSRJ0mau\ny4C4DOjvEdy1aXtEVd1eVQ80q2cCB/RtW9b8XAL8ENi/w1olSZLU6DIgzgNmJNkzyZbA0UBrNnKS\np/StHglc27TvkGSrZnkn4GBg9OQWSZIkdaCzWcxVtSrJCcDFwGTgrKpakOQ0YH5VzQVOTHIksApY\nARzXHL43cEaS1fRC7EfHmP0sSZKkDnQWEAGq6iLgolFtp/Qtvw943xjH/RjYt8vaJEmSNLZhT1KR\nJEnSY4wBUZIkSS0GREmSJLUYECVJktRiQJQkSVKLAVGSJEktBkRJkiS1GBAlSZLUYkCUJElSiwFR\nkiRJLQZESZIktRgQJUmS1GJAlCRJUosBUZIkSS0GREmSJLUYECVJktRiQJQkSVKLAVGSJEktBkRJ\nkiS1GBAlSZLUYkCUJElSiwFRkiRJLQZESZIktRgQJUmS1GJAlCRJUosBUZIkSS0GREmSJLUYECVJ\nktRiQJQkSVKLAVGSJEktBkRJkiS1dBoQkxyeZFGSxUlOHmP7cUmWJ7my+by5b9uxSX7VfI7tsk5J\nkiQ9akpXJ04yGTgdOBRYCsxLMreqFo7a9StVdcKoY3cEPgjMBgq4ojl2ZVf1SpIkqafLHsSDgMVV\ntaSqHgTOA44a8NiXApdU1YomFF4CHN5RnZIkSerTZUDcBbipb31p0zbaq5JcneRrSXZbz2MlSZI0\nzjobYh7QhcCXq+qBJP8FOBt4yaAHJzkeOL5ZvTvJog5q1GPbTsBvh13EMHyIDw27BGlj8u/6xLTH\nsAuYqLoMiMuA3frWd23aHlFVt/etngn8Q9+xLxp17A9HX6Cq5gBz/vBStalKMr+qZg+7Dknd8u+6\ntHF1OcQ8D5iRZM8kWwJHA3P7d0jylL7VI4Frm+WLgcOS7JBkB+Cwpk2SJEkd66wHsapWJTmBXrCb\nDJxVVQuSnAbMr6q5wIlJjgRWASuA45pjVyT5ML2QCXBaVa3oqlZJkiQ9KlU17BqkDZbk+OZWA0mb\nMf+uSxuXAVGSJEktvmpPkiRJLQZESZIktRgQJUmS1GJA1CYjyYFJXjZG+8uTHDCMmiRJ2hwZELUp\n+RiwcIz2BcA/buRaJHUoyQuTPLtZfk2STyU5KclWw65NmgiG/ao9aX08vqpuHN1YVTcm2WkYBUka\nf0lOB54NbJXkOmBb4DvAwcBZwOuGWJ40IRgQtSnZYS3bttloVUjq2ouralaSqfRevbpzVT2c5Azg\n6iHXJk0IDjFrU3Jpko8kyUhDek4Dvj/EuiSNr/sBqup+4MaqerhZL+ChYRYmTRT2IGpT8i7gX4DF\nSa5s2vYD5gNvHlpVksbbzkneCaRvmWZ92vDKkiYO36SiTU6SpwHPalYXVNWSYdYjaXwl+eDatlfV\nhzZWLdJEZUDUJiPJQuBLwHlVdf2w65EkaXNlQNQmI8l+wNHAa4DbgS8DX6mqm4damKRxleSUtWyu\nqvrwRitGmqAMiNokJXku8FrgVcD1wLlV9bnhViVpPCR51xjNjwPeBDyxqrbdyCVJE44BUZu0JC8C\n/hmYVVU+QFfazCR5PPB2euHwfODjVXXbcKuSNn/OYtYmJ8mBwDH0eg9vAM4AvjrUoiSNqyQ7Au+k\n91Dss4E/qqqVw61KmjgMiNpkJPl7evcfrgTOAw6uqqXDrUrSeEvyj8ArgTnAvlV195BLkiYch5i1\nyWhuXP9BVf2oWX8jvV7EG4FTq2rFMOuTND6SrAYeAFYB/f9Ihd4kle2GUpg0gRgQtclI8h/An1bV\niiQvoNeL+DbgOcDeVfXqoRYoSdJmwiFmbUom9fUSvhaYU1UXABf0vVlFkiT9gXwXszYlU5KM/Kfm\nENrvX/Y/O5IkjRP/UdWm5MvAZUl+C9wHjNyL+AzgzmEWJknS5sR7ELVJaR6Q/RTgu1V1T9M2E9i2\nqv5jqMVJkrSZMCBKkiSpxXsQJUmS1GJAlCRJUosBUZIkSS0GREmSJLUYECVJktTyfwGulrbFc+EA\ncwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}